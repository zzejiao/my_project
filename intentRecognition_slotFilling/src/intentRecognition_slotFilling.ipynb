{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your directory first\n",
    "woz_directory = \"./data/\"\n",
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz022MmySYUV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9zyxuLiSbFU"
   },
   "source": [
    "\n",
    "# 1. Constructing Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twa78ME9SYUV"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738477453342,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "p4laCr5lSYUV"
   },
   "outputs": [],
   "source": [
    "# please add all your imports here\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORehnH1OSYUV"
   },
   "source": [
    "## 1.1 Analyze the Training Data and Slots\n",
    "\n",
    "- The following Code Cell parse the  training targets and find how many slots are the in the training data answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1738477453667,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "luL75uPTSYUW"
   },
   "outputs": [],
   "source": [
    "def parse_target(line):\n",
    "    match = re.findall(r\"(\\w+-\\w+)=([\\w+\\s*&*]+)\", line)\n",
    "    slot_name = [m[0] for m in match]\n",
    "    slot_value = [m[1] for m in match]\n",
    "    return slot_name, slot_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1738477453667,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "CnnZ9xdxSYUW",
    "outputId": "23b4e53f-1980-4d88-b3a0-086483fd1aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hotel-area', 'hotel-internet', 'hotel-parking', 'hotel-name', 'restaurant-food', 'restaurant-pricerange', 'restaurant-area', 'restaurant-name', 'hotel-pricerange', 'hotel-stars', 'hotel-type'])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with open(woz_directory + \"WOZ_train_ans.txt\") as f:\n",
    "    train_answers = [answer.strip() for answer in f.readlines()]\n",
    "\n",
    "slot_mapping = defaultdict(set)\n",
    "\n",
    "for line in train_answers:\n",
    "    slot_name, slot_value = parse_target(line)\n",
    "    for i, name in enumerate(slot_name):\n",
    "        slot_mapping[name].add(slot_value[i])\n",
    "\n",
    "print(slot_mapping.keys())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# for key in slot_mapping:\n",
    "#     print(key, \"-----\", slot_mapping[key])\n",
    "#     print(len(slot_mapping[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifMZvJcFSYUW"
   },
   "source": [
    "### Statistics:\n",
    "- **Slots for Hotel:** 4\n",
    "    - {'stars', 'internet', 'parking', 'name', 'type', 'pricerange', 'area'}\n",
    "- **Slots for Restaurant:** 7\n",
    "    - {'pricerange', 'name', 'area', 'food'}\n",
    "- We have 4+7 = **11 slots in total**\n",
    "\n",
    "### The Slots can be divided into two categories:\n",
    "- **Closed Class**(Slots that have fixed Values):\n",
    "    - These slot values can be predefined and can be used to train a classifier.\n",
    "    - The following slots are closed class slots:\n",
    "```python\n",
    "dict_keys(['hotel-area', 'hotel-internet', 'hotel-parking', 'restaurant-pricerange', 'restaurant-area', 'hotel-pricerange', 'hotel-stars', 'hotel-type'])\n",
    "```\n",
    "- **Open Class**(Slots that have variable values):\n",
    "    - These slot values can be extracted using Named Entity Recognition(NER) or any other method.\n",
    "    - Slots like `name`,`food` in both hotel and restaurant are open class slots.\n",
    "```python\n",
    "['hotel-name', 'restaurant-food','restaurant-name']\n",
    "```\n",
    "### Missing Value\n",
    "- Sometimes the utterance suggests meaning like: \"Anything will be fine\", then the slot_value will be `dontcare`.\n",
    "- That does not equals to situation when \"slot not present in the target\" . We need to handle not-present slot.\n",
    "    - handled by adding \"not present\" to all the slots in `CLSOED_SLOTS[slot_name]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsdfXFK8SYUX"
   },
   "source": [
    "## 1.2 Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtReN7ahSYUX"
   },
   "source": [
    "###  Neural Network Model(BERT)\n",
    "\n",
    "#### Divided the Problem\n",
    "- After anallyzing the nature of the training target carefully. We realize that the problem can be divided into three parts:\n",
    "\n",
    "**Intent Classification**:\n",
    "- Find_hotel vs Find_restaurant\n",
    "    \n",
    "**Closed Class Slots-->sentence level classification:**\n",
    "- Closed Class Slots: The value for closed sometimes is not present in the utterance. It relies on the context.\n",
    "- The value is fixed, and the number of unique values is limited. This means the slot value can be predicted by convert **each closed class** slot to a **multi class** problem.\n",
    "\n",
    "**Open Class Slots-->NER-->token level labeling**\n",
    "- Convert this problem to Named Entity Recognition(NER) problem using BIO tagging. Because BERT can predict on sequence to sequence level.\n",
    "- Because the slot value here is not fixed,\n",
    "- and the number of unique values is large.\n",
    "- We need to extract the slot value from the utterance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmyMMXBgSYUX"
   },
   "source": [
    "#### Model Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1738477453667,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "bC7QJZxPdA6V"
   },
   "outputs": [],
   "source": [
    "class HybridSlot(nn.Module):\n",
    "    def __init__(self, model_name, closed_slots, num_BIO_tags):\n",
    "        super(HybridSlot, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # intent classification layer, 2 for 2 intents\n",
    "        self.intent = nn.Linear(self.hidden_size, 2)\n",
    "\n",
    "        # closed class slots layer\n",
    "        self.closed_slots = nn.ModuleDict(\n",
    "            {\n",
    "                slot_name: nn.Linear(self.hidden_size, len(slot_value))\n",
    "                for slot_name, slot_value in closed_slots.items()\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # open class slots layer\n",
    "        self.sequence_labeling = nn.Linear(self.hidden_size, num_BIO_tags)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        intent_label=None,\n",
    "        closed_slot_labels=None,\n",
    "        open_slot_labels=None,\n",
    "    ):\n",
    "\n",
    "        # Get BERT outputs(predictions)\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        tags_prediction = outputs[\n",
    "            0\n",
    "        ]  # for open slots, [batch_size, tags_length[32], hidden_size]\n",
    "        classification = outputs[\n",
    "            1\n",
    "        ]  # for intent and closed slots[batch_size, hidden_size]\n",
    "\n",
    "        # Apply dropout\n",
    "        classification = self.dropout(classification)\n",
    "        tags_prediction = self.dropout(tags_prediction)\n",
    "\n",
    "        # ----Get logits(probabilities) for all three tasks----\n",
    "\n",
    "        # 1. Intent Classification\n",
    "        intent_logits = self.intent(classification)  # [batch_size, 2]\n",
    "\n",
    "        # 2. Closed slots classification\n",
    "        closed_slots_logits = {}\n",
    "        for slot_name, layer in self.closed_slots.items():\n",
    "            closed_slots_logits[slot_name] = layer(classification)\n",
    "\n",
    "        # 3. Open slots sequence labeling\n",
    "        sequence_logits = self.sequence_labeling(\n",
    "            tags_prediction\n",
    "        )  # [batch_size, seq_length, num_BIO_tags]\n",
    "        ## ---------------------------------------------------\n",
    "\n",
    "        # -----------If we're training (labels provided), compute loss----------\n",
    "        if intent_label is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            total_loss = 0\n",
    "\n",
    "            # 1.Intent classification loss\n",
    "            intent_loss = loss_fct(intent_logits, intent_label)\n",
    "            total_loss += intent_loss\n",
    "\n",
    "            # 2.Closed slots classification loss\n",
    "            closed_slots_loss = 0\n",
    "            for slot_name in closed_slot_labels:\n",
    "                # Skip examples where slot is not present (-1)\n",
    "                valid_indices = closed_slot_labels[slot_name] != -1\n",
    "                if valid_indices.sum() > 0:\n",
    "                    valid_logits = closed_slots_logits[slot_name][valid_indices]\n",
    "                    valid_labels = closed_slot_labels[slot_name][valid_indices]\n",
    "                    closed_slots_loss += loss_fct(valid_logits, valid_labels)\n",
    "            total_loss += closed_slots_loss\n",
    "\n",
    "            # 3.Open slots sequence labeling loss\n",
    "            # Only compute loss on valid tokens (exclude padding)\n",
    "            active_loss = attention_mask.view(-1) == 1\n",
    "            active_logits = sequence_logits.view(-1, sequence_logits.shape[-1])[\n",
    "                active_loss\n",
    "            ]\n",
    "            active_labels = open_slot_labels.view(-1)[active_loss]\n",
    "\n",
    "            # Exclude padding tokens from loss computation\n",
    "            valid_label_mask = active_labels != 0  # Assuming 0 is padding index\n",
    "            if valid_label_mask.sum() > 0:\n",
    "                sequence_loss = loss_fct(\n",
    "                    active_logits[valid_label_mask], active_labels[valid_label_mask]\n",
    "                )\n",
    "                total_loss += sequence_loss\n",
    "\n",
    "            return total_loss\n",
    "\n",
    "        # If we're not training (no labels), return predictions\n",
    "        return intent_logits, closed_slots_logits, sequence_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxE-K_nnduUe",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 2. Prepare Training data:\n",
    "\n",
    "**Convert training data to format for model**\n",
    "\n",
    "## 2.1 Load training data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1067,
     "status": "ok",
     "timestamp": 1738477454728,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "77wVJquPSYUY",
    "outputId": "45003c16-2386-4884-ba8b-c90eef47c38d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_utterances: 3760\n",
      "Length of train_answers: 3760\n"
     ]
    }
   ],
   "source": [
    "with open(woz_directory + \"WOZ_train_utt.txt\") as f:\n",
    "    train_utterances = [answer.strip() for answer in f.readlines()]\n",
    "\n",
    "with open(woz_directory + \"WOZ_train_ans.txt\") as f:\n",
    "    train_answers = [answer.strip() for answer in f.readlines()]\n",
    "\n",
    "print(\"Length of train_utterances:\", len(train_utterances))\n",
    "print(\"Length of train_answers:\", len(train_answers))\n",
    "\n",
    "# initialze a tokenizer, we will use this to tokenize the utterance when extracting slots\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTPuwRw1SYUY"
   },
   "source": [
    "#### Examining some meta data:\n",
    "```python\n",
    "# all possible values for closed_slots\n",
    "# I add a \"notMentioned\"! in case slot is missing in the data\n",
    "CLOSED_SLOTS = {\n",
    "        hotel-area : {'centre', 'south', 'notMentioned', 'dontcare', 'east', 'west', 'north'} ,\n",
    "        hotel-internet : {'no', 'notMentioned', 'yes', 'dontcare'} ,\n",
    "        hotel-parking : {'no', 'notMentioned', 'yes', 'dontcare'} ,\n",
    "        restaurant-pricerange : {'expensive', 'notMentioned', 'dontcare', 'cheap', 'moderate'} ,\n",
    "        restaurant-area : {'centre', 'south', 'notMentioned', 'dontcare', 'east', 'west', 'north'} ,\n",
    "        hotel-pricerange : {'expensive', 'notMentioned', 'dontcare', 'cheap', 'moderate'} ,\n",
    "        hotel-stars : {'3', '2', 'notMentioned', 'dontcare', '4', '5', '1', '0'} ,\n",
    "        hotel-type : {'notMentioned', 'guesthouse', 'dontcare'} ,\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1738477454729,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "4s_NSUYfduAA",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "699d2a9a-6822-4195-ca74-ad6dfe94be57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel-area : {'dontcare', 'notMentioned', 'south', 'east', 'north', 'west', 'centre'} ,\n",
      "hotel-internet : {'yes', 'dontcare', 'no', 'notMentioned'} ,\n",
      "hotel-parking : {'yes', 'dontcare', 'no', 'notMentioned'} ,\n",
      "restaurant-pricerange : {'dontcare', 'notMentioned', 'cheap', 'moderate', 'expensive'} ,\n",
      "restaurant-area : {'dontcare', 'notMentioned', 'south', 'east', 'north', 'west', 'centre'} ,\n",
      "hotel-pricerange : {'dontcare', 'notMentioned', 'cheap', 'moderate', 'expensive'} ,\n",
      "hotel-stars : {'dontcare', '4', '3', 'notMentioned', '5', '2', '1', '0'} ,\n",
      "hotel-type : {'dontcare', 'notMentioned', 'guesthouse'} ,\n"
     ]
    }
   ],
   "source": [
    "OPEN_SLOT_NAMES = [\"hotel-name\", \"restaurant-food\", \"restaurant-name\"]\n",
    "CLOSED_SLOT_NAMES = [\n",
    "    \"hotel-area\",\n",
    "    \"hotel-internet\",\n",
    "    \"hotel-parking\",\n",
    "    \"restaurant-pricerange\",\n",
    "    \"restaurant-area\",\n",
    "    \"hotel-pricerange\",\n",
    "    \"hotel-stars\",\n",
    "    \"hotel-type\",\n",
    "]\n",
    "\n",
    "\n",
    "OPEN_SLOTS = defaultdict(set)\n",
    "CLOSED_SLOTS = slot_mapping.copy()  # WE KEEP THESE TO PASS TO BERT MODEL\n",
    "\n",
    "for slot_name in OPEN_SLOT_NAMES:\n",
    "    OPEN_SLOTS[slot_name] = slot_mapping[slot_name]\n",
    "    # remove the open slots from closed slots\n",
    "    CLOSED_SLOTS.pop(slot_name)\n",
    "\n",
    "\n",
    "# to handle missing slots\n",
    "for slot in CLOSED_SLOTS:\n",
    "    CLOSED_SLOTS[slot].add(\"notMentioned\")\n",
    "    print(slot, \":\", CLOSED_SLOTS[slot], \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL0woYTiePqk"
   },
   "source": [
    "## 2.2 Extract target from Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij_ypVfCSYUZ"
   },
   "source": [
    "### Extract Intent from single example\n",
    "\n",
    "**Intent mapping**\n",
    "```python\n",
    "intent = {\n",
    "        \"find_hotel\": 0,\n",
    "        \"find_restaurant\": 1\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1738477454730,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "XLd2evrJc_cM"
   },
   "outputs": [],
   "source": [
    "def extract_intent(answer):\n",
    "    \"\"\"convert intent for a single example\"\"\"\n",
    "    intent = answer.split(\"|\")[0]\n",
    "    if intent == \"find_hotel\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElAtzWx5SYUa",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Extract slots from single example\n",
    "\n",
    "**Closed Slots:**\n",
    "```python\n",
    "closed_slots = {'hotel-area': 'centre', 'hotel-internet': 'yes', 'hotel-parking': 'yes'}\n",
    "```\n",
    "\n",
    "**Open Slots: convert slot to BIO-tag**\n",
    "\n",
    "```python\n",
    "utterance = \"Hi there! Can you give me some info on Cityroomz?\"\n",
    "answer = \"find_hotel|hotel-name=cityroomz\" # ---> conver to BIO tag by\n",
    "\n",
    "#1. split utterance\n",
    "tokens = ['Hi', 'there!', 'Can', 'you', 'give', 'me', 'some', 'info', 'on', 'Cityroomz?']\n",
    "\n",
    "# 2.tag them\n",
    "slot_tag = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-hotel-name']\n",
    "\n",
    "# after Bert Tokenizer, words will be splitted into differnt subword/morphemes, So we will need to align the tags\n",
    "\n",
    "```\n",
    "\n",
    "**the output of this funtion look like:**\n",
    "```python\n",
    "closed_slots = {'hotel-area': 'centre', 'hotel-internet': 'yes', 'hotel-parking': 'yes'}\n",
    "BIO_tag = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-hotel-name']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1738477454730,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "IqJEVsv5QW84",
    "outputId": "c07fa721-a93a-4293-c06c-189b2fd84f76",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize sentence\n",
    "\n",
    "\n",
    "def extract_slot(answer, utterance, tokenizer, CLOSED_SLOT_NAMES, OPEN_SLOT_NAMES):\n",
    "    \"\"\"convert closed_slot, open_slot for a single example\"\"\"\n",
    "\n",
    "    closed_slots = {}\n",
    "    tokens = tokenizer.tokenize(utterance)\n",
    "\n",
    "    # initialize BIO tag to contain only 'O'\n",
    "    BIO_tag = [\"O\"] * len(tokens)\n",
    "\n",
    "    slot_names, slot_values = parse_target(answer)\n",
    "\n",
    "    for slot_name, slot_value in zip(slot_names, slot_values):\n",
    "        if slot_name in CLOSED_SLOT_NAMES:\n",
    "            closed_slots[slot_name] = slot_value\n",
    "\n",
    "        elif slot_name in OPEN_SLOT_NAMES:\n",
    "            # giving tags to the tokenized utterance\n",
    "            slot_subwords = tokenizer.tokenize(slot_value)\n",
    "\n",
    "            # find out which part of the tokens match the slot_value_tokenized\n",
    "            # give them tags(slot_name)\n",
    "            for i in range(len(tokens) - len(slot_subwords) + 1):\n",
    "                if tokens[i : i + len(slot_subwords)] == slot_subwords:\n",
    "                    BIO_tag[i] = \"B-\" + slot_name\n",
    "                    for j in range(1, len(slot_subwords)):\n",
    "                        BIO_tag[i + j] = \"I-\" + slot_name\n",
    "    # print(tokens)\n",
    "    # print(BIO_tag)\n",
    "    return closed_slots, BIO_tag\n",
    "\n",
    "\n",
    "# i = 2\n",
    "# extract_slot(train_answers[i], train_utterances[i],tokenizer,CLOSED_SLOT_NAMES, OPEN_SLOT_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyZ3qjoISYUb"
   },
   "source": [
    "### Pack examples from`train_X and train_y`\n",
    "\n",
    "**Sample parsed training answer**\n",
    "\n",
    "```python\n",
    "example = {\n",
    "        \"intent\" : 0,\n",
    "        \"closed_slots\": {\n",
    "                        \"hotel-area\" : 'north',\n",
    "                        \"hotel-internet\" : 'yes'\n",
    "                        },\n",
    "        \"open_slots\" : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-hotel-name']\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738477454730,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "kBYVEEdiSYUb",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pack_examples(\n",
    "    train_answers, train_utterances, tokenizer, CLOSED_SLOT_NAMES, OPEN_SLOT_NAMES\n",
    "):\n",
    "    examples = []\n",
    "    for answer, utterance in zip(train_answers, train_utterances):\n",
    "        example = {}\n",
    "\n",
    "        example[\"utterance\"] = utterance\n",
    "\n",
    "        intent = extract_intent(answer)\n",
    "        example[\"intent\"] = intent\n",
    "\n",
    "        closed_slots, BIO_tags = extract_slot(\n",
    "            answer, utterance, tokenizer, CLOSED_SLOT_NAMES, OPEN_SLOT_NAMES\n",
    "        )\n",
    "\n",
    "        example[\"closed_slots\"] = closed_slots\n",
    "        example[\"open_slots\"] = BIO_tags\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HYxjT-zSYUc"
   },
   "source": [
    "### Convert the values to id using above Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1738477455851,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "J4cj7_1RSYUc",
    "outputId": "600aa755-2101-4f0b-9567-89eab8fc0ec8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value2id_MAPPING = {\n",
    "    slot_name: {v: i for i, v in enumerate(slot_mapping[slot_name])}\n",
    "    for slot_name in CLOSED_SLOT_NAMES\n",
    "}\n",
    "\n",
    "id2value_MAPPING = {\n",
    "    slot_name: {i: v for i, v in enumerate(slot_mapping[slot_name])}\n",
    "    for slot_name in CLOSED_SLOT_NAMES\n",
    "}\n",
    "\n",
    "\n",
    "tag2id = {\n",
    "    \"[PAD]\": 0,  # padding\n",
    "    \"O\": 1,\n",
    "    \"B-hotel-name\": 2,\n",
    "    \"I-hotel-name\": 3,\n",
    "    \"B-restaurant-food\": 4,\n",
    "    \"I-restaurant-food\": 5,\n",
    "    \"B-restaurant-name\": 6,\n",
    "    \"I-restaurant-name\": 7,\n",
    "}\n",
    "id2tag = {v: k for k, v in tag2id.items()}\n",
    "\n",
    "# print(value2id_MAPPING)\n",
    "# print(id2value_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1738477455851,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "CIVs4k-WSYUc"
   },
   "outputs": [],
   "source": [
    "def convert_to_ids(examples, CLOSED_SLOT_NAMES, value2id_MAPPING):\n",
    "    \"\"\"convert the values\"\"\"\n",
    "    converted_examples = []\n",
    "\n",
    "    for example in examples:\n",
    "        new_example = {}\n",
    "        new_example[\"intent\"] = example[\"intent\"]\n",
    "        new_example[\"utterance\"] = example[\"utterance\"]\n",
    "        new_example[\"closed_slots\"] = example[\n",
    "            \"closed_slots\"\n",
    "        ].copy()  # Create a deep copy to avoid modifying original\n",
    "        # Create a deep copy to avoid modifying original\n",
    "\n",
    "        # convert closed slots to ids\n",
    "        for slot_name in CLOSED_SLOT_NAMES:\n",
    "            if slot_name in example[\"closed_slots\"]:\n",
    "                # slot_name is like hotel-area, hotel-interne\n",
    "                slot_value = example[\"closed_slots\"][slot_name]\n",
    "                # like yes, no, dontcare\n",
    "                \n",
    "                try:\n",
    "                    new_example[\"closed_slots\"][slot_name] = value2id_MAPPING[slot_name][slot_value]\n",
    "                except KeyError:\n",
    "                    new_example[\"closed_slots\"][slot_name] = value2id_MAPPING[slot_name][\"notMentioned\"]\n",
    "\n",
    "            else:\n",
    "                new_example[\"closed_slots\"][slot_name] = value2id_MAPPING[slot_name][\n",
    "                    \"notMentioned\"\n",
    "                ]  # 10 for slot not present\n",
    "\n",
    "        open_ids = [tag2id[tag] for tag in example[\"open_slots\"]]\n",
    "        new_example[\"open_slots\"] = open_ids\n",
    "\n",
    "        converted_examples.append(new_example)\n",
    "\n",
    "    return converted_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1738477455851,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "n5-apuSuSYUl",
    "outputId": "1da131e9-8a13-494d-a2e1-fc4769a81615"
   },
   "outputs": [],
   "source": [
    "# example_ids = convert_to_ids(train_examples, CLOSED_SLOTS, value2id_MAPPING)\n",
    "# example_ids[100]['closed_slots']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rakZ6LxSYUl"
   },
   "source": [
    "## Convert to batch Tensor\n",
    "\n",
    "```python\n",
    "batch = {\n",
    "intent_label = torch.tensor([0, 1, 0, ..., 1])  # shape(batch_size,1)\n",
    ",\n",
    "closed_slots = {\n",
    "    \"hotel-area\": torch.tensor([0, 2, 1, ..., 3]),      # shape [batch_size, 1]\n",
    "    \"hotel-internet\": torch.tensor([1, 2, 0, ..., 2]),  # shape [batch_size, 1]\n",
    "...\n",
    "},\n",
    "open_slot_labels = torch.tensor([  # shape[batch_size, max_length]\n",
    "    [0, 0, 1, 2, 0, ..., 0],  # tags of first utterance\n",
    "    [0, 3, 4, 0, ..., 0],     # tags of second utteranc\n",
    "    ... # 16 utterance in example\n",
    "])\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1738477456784,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "mWXoSSDxSYUm",
    "outputId": "6a9c05cc-82d4-4fea-8d32-8173d2c0534d"
   },
   "outputs": [],
   "source": [
    "# # Check max length in your dataset\n",
    "# max_len = 0\n",
    "# total_len = 0\n",
    "# for example in train_examples:\n",
    "#     tokens = tokenizer.tokenize(example[\"utterance\"])\n",
    "#     max_len = max(max_len, len(tokens))\n",
    "#     total_len += len(tokens)\n",
    "# print(\"total length of tokens\", total_len)\n",
    "# print(f\"Average sequence length in dataset: {total_len / len(train_examples)}\")\n",
    "# print(f\"Maximum sequence length in dataset: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1738477456785,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "BH9dFBQESYUm"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 128  # because the maximum length of the sequence is below 128\n",
    "\n",
    "\n",
    "def collate_fn(batched_examples, MAX_LEN):\n",
    "    \"\"\"convert the examples to batch tensor\"\"\"\n",
    "    # Tokenize all utterances in the batch\n",
    "    utterances = [example[\"utterance\"] for example in batched_examples]\n",
    "    encoded = tokenizer(\n",
    "        utterances,\n",
    "        padding=True,\n",
    "        truncation=False,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Get the actual sequence length after tokenization\n",
    "    seq_length = encoded[\"input_ids\"].size(1)\n",
    "\n",
    "    batch = {\n",
    "        \"input_ids\": encoded[\"input_ids\"],\n",
    "        \"attention_mask\": encoded[\"attention_mask\"],\n",
    "        \"intent\": torch.tensor([example[\"intent\"] for example in batched_examples]),\n",
    "    }\n",
    "\n",
    "    # convert closed slots to batches\n",
    "    batch[\"closed_slots\"] = {}\n",
    "    for slot_name in CLOSED_SLOT_NAMES:\n",
    "        batch[\"closed_slots\"][slot_name] = torch.tensor(\n",
    "            [example[\"closed_slots\"][slot_name] for example in batched_examples]\n",
    "        )\n",
    "\n",
    "    # covert open slots and pad to the SAME length as input_ids\n",
    "    padded_open_slots = torch.zeros(len(batched_examples), seq_length, dtype=torch.long)\n",
    "    for i, example in enumerate(batched_examples):\n",
    "        length = min(len(example[\"open_slots\"]), seq_length)\n",
    "        padded_open_slots[i, :length] = torch.tensor(example[\"open_slots\"][:length])\n",
    "\n",
    "    batch[\"open_slots\"] = padded_open_slots\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1738477456785,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "FdcFbCPlSYUn",
    "outputId": "1989eb18-707e-4107-d0c6-cd4e11a16c78"
   },
   "outputs": [],
   "source": [
    "# collate_fn(example_ids[:BATCH_SIZE], MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlHDxQWpSYUn"
   },
   "source": [
    "## Load to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1738477456785,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "_V2l9H5qSYUo"
   },
   "outputs": [],
   "source": [
    "class SlotFillingDataset(Dataset):\n",
    "    def __init__(self, examples, tokenizer, max_len=32):\n",
    "        self.examples = examples\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "\n",
    "def create_dataloader(utt_path, answers_path):\n",
    "    with open(utt_path) as f:\n",
    "        utterances = [line.strip() for line in f.readlines()]\n",
    "    with open(answers_path) as f:\n",
    "        answers = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # 1.Create examples\n",
    "    examples = pack_examples(\n",
    "        answers, utterances, tokenizer, CLOSED_SLOT_NAMES, OPEN_SLOT_NAMES\n",
    "    )\n",
    "\n",
    "    # 2.Convert to ids\n",
    "    examples_ids = convert_to_ids(examples, CLOSED_SLOTS, value2id_MAPPING)\n",
    "\n",
    "    # 3.Create datasets\n",
    "    dataset = SlotFillingDataset(examples_ids, tokenizer, MAX_LEN)\n",
    "\n",
    "    # 4. Create data loaders\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda x: collate_fn(x, MAX_LEN),\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1738477456786,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "ApjmlddrSYUo"
   },
   "outputs": [],
   "source": [
    "train_loader = create_dataloader(woz_directory + \"WOZ_train_utt.txt\", woz_directory + \"WOZ_train_ans.txt\")\n",
    "dev_loader = create_dataloader(woz_directory + \"WOZ_dev_utt.txt\", woz_directory + \"WOZ_dev_ans.txt\")\n",
    "test_loader = create_dataloader(woz_directory + \"WOZ_test_utt.txt\", woz_directory + \"WOZ_test_ans.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Keys: dict_keys(['input_ids', 'attention_mask', 'intent', 'closed_slots', 'open_slots'])\n",
      "Input IDs: torch.Size([32, 34])\n",
      "First 5 Input IDs:\n",
      " tensor([[  101,  9535,  2368,  6415,  1010,  1045,  2572,  6595, 11585,  1999,\n",
      "          4729,  1998,  2342,  1037,  2173,  2000,  3637,  1012,  1045,  2342,\n",
      "          2489,  5581,  1998,  4274,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  7632,  2045,   999,  2064,  2017,  2507,  2033,  2070, 18558,\n",
      "          2006,  2103,  9954,  2480,  1029,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2559,  2005,  1037,  3309,  2315,  2632, 23147,\n",
      "         10024,  2100,  7410,  4113,  2160,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2559,  2005,  1037,  4825,  1012,  1045,  2052,\n",
      "          2066,  2242, 10036,  2008,  2038,  2822,  2833,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1045,  1005,  1049,  2559,  2005,  2019,  6450,  4825,  1999,\n",
      "          1996,  2803,  2065,  2017,  2071,  2393,  2033,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]])\n",
      "First 5 Intent Labels:\n",
      " tensor([0, 0, 0, 1, 1])\n",
      "First 5 Open Slot Labels:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\miniforge3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get a single batch\n",
    "for batch in train_loader:\n",
    "    print(\"Batch Keys:\", batch.keys())  # Check what keys are in the batch\n",
    "    print(\"Input IDs:\", batch[\"input_ids\"].shape)  # Inspect tensor shape\n",
    "    print(\"First 5 Input IDs:\\n\", batch[\"input_ids\"][:5])  # Inspect first few examples\n",
    "    print(\"First 5 Intent Labels:\\n\", batch[\"intent\"][:5])\n",
    "    print(\"First 5 Open Slot Labels:\\n\", batch[\"open_slots\"][:5])\n",
    "    break  # Stop after printing one batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ns5hRczVSYUp"
   },
   "source": [
    "---\n",
    "# 3. Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2_EKAlOSYUp"
   },
   "source": [
    "## 3.1 baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1149798,
     "status": "ok",
     "timestamp": 1738478606575,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "6N9vxYUKSYUp"
   },
   "outputs": [],
   "source": [
    "num_BIO_tags = len(tag2id)  # pass this to BERT when initializing the model\n",
    "\n",
    "model = HybridSlot(model_name, CLOSED_SLOTS, num_BIO_tags)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# for epoch in range(3):\n",
    "#     model.train()\n",
    "#     for batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = model(\n",
    "#             input_ids=batch[\"input_ids\"],\n",
    "#             attention_mask=batch[\"attention_mask\"],\n",
    "#             intent_label=batch[\"intent\"],\n",
    "#             closed_slot_labels=batch[\"closed_slots\"],\n",
    "#             open_slot_labels=batch[\"open_slots\"],\n",
    "#         )\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Evaluate on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\miniforge3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent Accuracy: 0.4746\n",
      "Open Slot F1 Score: 0.0219\n",
      "\n",
      "hotel-area F1 Score: 0.0027\n",
      "hotel-internet F1 Score: 0.0000\n",
      "hotel-parking F1 Score: 0.0411\n",
      "restaurant-pricerange F1 Score: 0.0220\n",
      "restaurant-area F1 Score: 0.0061\n",
      "hotel-pricerange F1 Score: 0.0093\n",
      "hotel-stars F1 Score: 0.1120\n",
      "hotel-type F1 Score: 0.0515\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, eval_loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "\n",
    "    intent_preds, intent_true = [], []\n",
    "    closed_slot_preds, closed_slot_true = {}, {}\n",
    "    open_slot_preds, open_slot_true = [], []\n",
    "\n",
    "    # Initialize prediction lists for each slot\n",
    "    for slot_name in model.closed_slots.keys():\n",
    "        closed_slot_preds[slot_name] = []\n",
    "        closed_slot_true[slot_name] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            # Move batch to device if needed\n",
    "            # I didn't! because I'm using CPU\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            attention_mask = batch[\"attention_mask\"]\n",
    "\n",
    "            # Get model predictions\n",
    "            intent_logits, closed_slot_logits, sequence_logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "\n",
    "            # Process intent predictions\n",
    "            intent_pred_values = intent_logits.argmax(dim=-1).cpu().numpy()\n",
    "            intent_preds.extend(intent_pred_values)\n",
    "            intent_true.extend(batch[\"intent\"].numpy())\n",
    "\n",
    "            # Process closed slot predictions\n",
    "            for slot_name, slot_preds in closed_slot_logits.items():\n",
    "                pred_values = slot_preds.argmax(dim=-1).cpu().numpy()\n",
    "                closed_slot_preds[slot_name].extend(pred_values)\n",
    "                closed_slot_true[slot_name].extend(\n",
    "                    batch[\"closed_slots\"][slot_name].numpy()\n",
    "                )\n",
    "\n",
    "            # Process open slot predictions (BIO tagging)\n",
    "            sequence_pred_values = sequence_logits.argmax(dim=-1).cpu().numpy()\n",
    "            attention_mask_np = batch[\"attention_mask\"].cpu().numpy()\n",
    "\n",
    "            for i in range(len(sequence_pred_values)):\n",
    "                true_labels = batch[\"open_slots\"][i].cpu().numpy()\n",
    "                pred_labels = sequence_pred_values[i]\n",
    "\n",
    "                # Mask padding tokens (only keep real words)\n",
    "                actual_seq_len = attention_mask_np[i].sum()\n",
    "                open_slot_true.extend(true_labels[:actual_seq_len])\n",
    "                open_slot_preds.extend(pred_labels[:actual_seq_len])\n",
    "\n",
    "    intent_accuracy = accuracy_score(intent_true, intent_preds)\n",
    "    open_slot_metrics = f1_score(open_slot_true, open_slot_preds, average=\"macro\")\n",
    "\n",
    "    # print(f\"Intent Accuracy: {intent_accuracy:.4f}\")\n",
    "    # print(f\"Open Slot F1 Score: {open_slot_metrics:.4f}\")\n",
    "\n",
    "    closed_slot_metrics = {}\n",
    "    # Calculate metrics for each closed slot\n",
    "    for slot_name in model.closed_slots.keys():\n",
    "        slot_preds = closed_slot_preds[slot_name]\n",
    "        slot_labels = closed_slot_true[slot_name]\n",
    "\n",
    "        closed_slot_metrics[slot_name] = f1_score(\n",
    "            slot_labels, slot_preds, average=\"macro\"\n",
    "        )\n",
    "\n",
    "    return intent_accuracy, closed_slot_metrics, open_slot_metrics\n",
    "\n",
    "\n",
    "eval_results = evaluate_model(model, dev_loader)\n",
    "print(f\"Intent Accuracy: {eval_results[0]:.4f}\")\n",
    "print(f\"Open Slot F1 Score: {eval_results[2]:.4f}\\n\")\n",
    "for slot_name, f1 in eval_results[1].items():\n",
    "    print(f\"{slot_name} F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\miniforge3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 1\n",
      "Train Loss: 6.9138\n",
      "\n",
      "Intent Accuracy: 0.9855\n",
      "Open Slot F1 Score: 0.1137\n",
      "\n",
      "hotel-area F1 Score: 0.1362\n",
      "hotel-internet F1 Score: 0.4732\n",
      "hotel-parking F1 Score: 0.2363\n",
      "restaurant-pricerange F1 Score: 0.2206\n",
      "restaurant-area F1 Score: 0.1448\n",
      "hotel-pricerange F1 Score: 0.2373\n",
      "hotel-stars F1 Score: 0.1914\n",
      "hotel-type F1 Score: 0.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\miniforge3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 2\n",
      "Train Loss: 3.2681\n",
      "\n",
      "Intent Accuracy: 0.9952\n",
      "Open Slot F1 Score: 0.2978\n",
      "\n",
      "hotel-area F1 Score: 0.1362\n",
      "hotel-internet F1 Score: 0.9867\n",
      "hotel-parking F1 Score: 0.4691\n",
      "restaurant-pricerange F1 Score: 0.8002\n",
      "restaurant-area F1 Score: 0.2550\n",
      "hotel-pricerange F1 Score: 0.2373\n",
      "hotel-stars F1 Score: 0.2446\n",
      "hotel-type F1 Score: 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\miniforge3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 3\n",
      "Train Loss: 2.2676\n",
      "\n",
      "Intent Accuracy: 0.9976\n",
      "Open Slot F1 Score: 0.5629\n",
      "\n",
      "hotel-area F1 Score: 0.1843\n",
      "hotel-internet F1 Score: 0.9867\n",
      "hotel-parking F1 Score: 0.4730\n",
      "restaurant-pricerange F1 Score: 0.9580\n",
      "restaurant-area F1 Score: 0.4103\n",
      "hotel-pricerange F1 Score: 0.3045\n",
      "hotel-stars F1 Score: 0.3512\n",
      "hotel-type F1 Score: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\miniforge3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 4\n",
      "Train Loss: 1.6595\n",
      "\n",
      "Intent Accuracy: 0.9976\n",
      "Open Slot F1 Score: 0.7609\n",
      "\n",
      "hotel-area F1 Score: 0.2001\n",
      "hotel-internet F1 Score: 0.9867\n",
      "hotel-parking F1 Score: 0.4705\n",
      "restaurant-pricerange F1 Score: 0.9778\n",
      "restaurant-area F1 Score: 0.4206\n",
      "hotel-pricerange F1 Score: 0.7787\n",
      "hotel-stars F1 Score: 0.3434\n",
      "hotel-type F1 Score: 0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\miniforge3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 5\n",
      "Train Loss: 1.3072\n",
      "\n",
      "Intent Accuracy: 0.9976\n",
      "Open Slot F1 Score: 0.8222\n",
      "\n",
      "hotel-area F1 Score: 0.3527\n",
      "hotel-internet F1 Score: 0.9867\n",
      "hotel-parking F1 Score: 0.4705\n",
      "restaurant-pricerange F1 Score: 0.9752\n",
      "restaurant-area F1 Score: 0.6080\n",
      "hotel-pricerange F1 Score: 0.9429\n",
      "hotel-stars F1 Score: 0.3405\n",
      "hotel-type F1 Score: 0.9624\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "# Move batch to device if needed, I didn't! because I don't have one!\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            intent_label=batch[\"intent\"],\n",
    "            closed_slot_labels=batch[\"closed_slots\"],\n",
    "            open_slot_labels=batch[\"open_slots\"],\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Evaluation phase\n",
    "    eval_results = evaluate_model(model, dev_loader)\n",
    "\n",
    "    # Print metrics\n",
    "    print('-'*50)\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    print(f\"Train Loss: {train_loss / len(train_loader):.4f}\\n\")\n",
    "    print(f\"Intent Accuracy: {eval_results[0]:.4f}\")\n",
    "    print(f\"Open Slot F1 Score: {eval_results[2]:.4f}\\n\")\n",
    "    for slot_name, f1 in eval_results[1].items():\n",
    "        print(f\"{slot_name} F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5pruA-GSYUq"
   },
   "source": [
    "---\n",
    "# 4. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    intent_preds = []\n",
    "    closed_slot_preds = {}\n",
    "    open_slot_preds = []\n",
    "\n",
    "    # initiate closed slots dict\n",
    "    for slot_name in model.closed_slots.keys():\n",
    "        closed_slot_preds[slot_name] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch_x = {k: v for k, v in batch.items()}\n",
    "            \n",
    "            intent_logits, closed_slot_logits, sequence_logits = model(\n",
    "                input_ids=batch_x[\"input_ids\"],\n",
    "                attention_mask=batch_x[\"attention_mask\"],\n",
    "            )\n",
    "\n",
    "            intent_pred_values = intent_logits.argmax(dim=-1).cpu().numpy()\n",
    "            intent_preds.extend(intent_pred_values)\n",
    "\n",
    "            for slot_name, slot_logits in closed_slot_logits.items():\n",
    "                pred_values = slot_logits.argmax(dim=-1).cpu().numpy()\n",
    "                closed_slot_preds[slot_name].extend(pred_values)\n",
    "\n",
    "            sequence_pred_values = sequence_logits.argmax(dim=-1).cpu().numpy()\n",
    "            attention_mask_np = batch[\"attention_mask\"].cpu().numpy()\n",
    "\n",
    "            for i in range(len(sequence_pred_values)):\n",
    "                pred_labels = sequence_pred_values[i]\n",
    "                actual_seq_len = attention_mask_np[i].sum()\n",
    "                open_slot_preds.append(pred_labels[:actual_seq_len])\n",
    "\n",
    "    return intent_preds, closed_slot_preds, open_slot_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\miniforge3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# run on GPU if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "# print(\"Device:\", device)\n",
    "\n",
    "train_preds_intent, train_preds_closed, train_preds_open = get_predictions(model, train_loader)\n",
    "dev_preds_intent, dev_preds_closed, dev_preds_open = get_predictions(model, dev_loader)\n",
    "\n",
    "test_preds_intent, test_preds_closed, test_preds_open = get_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5pruA-GSYUq"
   },
   "source": [
    "---\n",
    "# 5. Convert the model output to the final output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1738480419037,
     "user": {
      "displayName": "Zhengyi Shan",
      "userId": "16734884872471528554"
     },
     "user_tz": 480
    },
    "id": "S_0E2Sh7SYUq",
    "outputId": "9c4099cc-6c3f-4552-d68c-0393487a7a83"
   },
   "outputs": [],
   "source": [
    "def convert_intent(intent_preds):\n",
    "    \"\"\"take in a list of intent predctions\"\"\"\n",
    "    return [\"find_restaurant\" if intent else \"find_hotel\" for intent in intent_preds]\n",
    "\n",
    "def convert_closed_slots(closed_slot_preds, id2value):\n",
    "    predictions = []\n",
    "    \"\"\"take in a dictionary of closed slot predictions\"\"\"\n",
    "    # iterate over all examples\n",
    "    for i in range(len(closed_slot_preds[\"hotel-area\"])):\n",
    "        results = {}\n",
    "        for slot_name in closed_slot_preds:\n",
    "            pred_id = closed_slot_preds[slot_name][i]\n",
    "            pred_value = id2value[slot_name][pred_id]\n",
    "            if pred_value != \"notMentioned\":\n",
    "                results[slot_name] = pred_value\n",
    "        predictions.append(results)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predicted_slots(open_slot_preds, input_ids, tokenizer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        open_slot_preds: predictions, usually loader[2]\n",
    "    Returns:\n",
    "        extracted_texts: texted corresponding to predictions\n",
    "        extracted_labels: id of predicted tag, like 3(id): hotel-name,\n",
    "    \"\"\"\n",
    "    extracted_texts = []\n",
    "    extracted_labels = []\n",
    "\n",
    "    for idx, (preds, ids) in enumerate(zip(open_slot_preds, input_ids)):\n",
    "        tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "        slot_text = []\n",
    "        slot_labels = []\n",
    "        \n",
    "        for token, pred in zip(tokens, preds):\n",
    "            if pred > 1:\n",
    "                slot_text.append(token)\n",
    "                if pred % 2 == 0:\n",
    "                    slot_labels.append(pred)\n",
    "        \n",
    "        if slot_text:\n",
    "            extracted_texts.append(tokenizer.convert_tokens_to_string(slot_text))\n",
    "            extracted_labels.append(slot_labels)\n",
    "\n",
    "    return extracted_texts, extracted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_open_slots(open_slot_preds, slot_predictions, dataloader, tokenizer):\n",
    "\n",
    "    for batch in dev_loader:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        # extract the open slot values\n",
    "        extracted_texts, extracted_labels = extract_predicted_slots(\n",
    "            open_slot_preds, input_ids, tokenizer\n",
    "        )\n",
    "        \n",
    "        # adding open_slot predictions to the slot_predictions dict\n",
    "        for i in range(len(extracted_texts)):\n",
    "            tags = extracted_labels[i]\n",
    "            for tag in tags:\n",
    "                slot_name = id2tag[tag][2:]\n",
    "                slot_predictions[i][slot_name] = extracted_texts[i]\n",
    "    return slot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\miniforge3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "intent_predictions = convert_intent(dev_preds_intent)\n",
    "slot_predictions = convert_closed_slots(dev_preds_closed, id2value_MAPPING)\n",
    "slot_predictions = convert_open_slots(dev_preds_open, slot_predictions, dev_loader, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n",
      "413\n",
      "['find_restaurant', 'find_hotel', 'find_restaurant', 'find_hotel', 'find_hotel']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'restaurant-area': 'centre', 'restaurant-food': 'local'},\n",
       " {'restaurant-food': 'cheap'},\n",
       " {'restaurant-pricerange': 'expensive',\n",
       "  'restaurant-area': 'centre',\n",
       "  'restaurant-food': 'food'},\n",
       " {'hotel-parking': 'yes', 'restaurant-name': 'food restaurant in'},\n",
       " {'hotel-internet': 'yes',\n",
       "  'hotel-pricerange': 'expensive',\n",
       "  'restaurant-food': 'find'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(intent_predictions))\n",
    "print(len(slot_predictions))\n",
    "print(intent_predictions[:5])\n",
    "slot_predictions[:5]\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
